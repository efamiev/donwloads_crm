## Нужно разработать JSON API со следующим функционалом:

## Модели:
***

#### Project
  - uuid
  - name (обязательное поле)
  - description
  - price (обязательное поле)
  - has_many: tasks
#### Task
  - uuid
  - name (обязательное поле)
  - description
  - estimate date (необязательно поле, но не может быть в прошлом)
  - price (необязательно поле, но сумма стоимостей задач не может превышать стоимость проекта)
  - urls (массив урлов, должен быть хотя бы 1 урл)
  - status (может иметь такие значения - initialized, processing, failed, finished)
  - progress (от 0 до 100%)
  - belongs_to: project

## Эндпоинты:
***

#### **GET /projects** - возвращает список проектов с полями:
  - price
  - estimate date (берется самая поздняя дата из estimate date задач)
  - status (берется самый низкий status из задач)
  - progress (берется самое меньшее из значений progress из задач)
  - tasks_count (количество задач в проекте)

#### **POST /projects** - создается проект (в body передаются поля - name, description, price)

#### **GET /tasks** - возвращает список задач с полями (uuid, name, description, estimate date, price, status, progress, project). Поля для проекта такие же, как и в списке проектов.

#### **POST /tasks/batch_create** - массовое создание задач.
  * В массиве передаются поля (name, description, estimate date, price, urls, project_id) - из них создаются задачи.

#### **POST /tasks/batch_update** - массовое обновление задач.
  * В массиве передаются поля (name, description, estimate date, price, urls, task_id) - происходит обновление переданных полей у задач из массива. В массиве может присутствовать любой набор полей.


## Функционал:
***

1. При создании задачи - ей передается поле urls, в котором указываются ссылки на файлы. Это могут быть любые ссылки на любом сайте, единственное условие - это должны быть ссылки именно на файлы. После создания задачи эти файлы объединяются в архив и этот архив закачивается на AWS S3. К примеру: в поле urls было передано 3 ссылки - https://site.com/logo1.png, https://site.com/logo2.png, https://site.com/logo3.png .

2. Они должны быть объединены в один архив и этот архив должен быть закачан на S3. Сами файлы на S3 закачивать не нужно, только архив.

3. После начала формирования архива у задачи меняется поле status на processing, в случае ошибки - меняется на failed, после завершения - на finished

4. По ходу формирования архива - меняется поле progress, в котором должно указываться кол-во процентов, на которые архив сформирован

5. При изменении любого из полей задачи - информация об этом отправляется по websockets

6. После завершения формирования архива, по websockets отправляется ссылка на сформированный архив

## Пожелания:
***

* Нужно разработать именно API, клиентская часть не нужна
* Авторизация не нужна
* База - PostgreSQL
* Названия таблиц, столбцов, полей, файлов, методов, классов - все можно менять на ваше усмотрение
* К схеме работы websockets особых требований нет - реализация на ваше усмотрение (лишь бы соблюдался необходимый функционал)
* Приложение небольшое, но нужно заложить возможность для его масштабирования. Уже на следующем этапе добавится несколько моделей со схожим набором полей, но немного другим функционалом
* Не смотря на то, что приложение маленькое - оно должно быть законченным - ошибки должны отдаваться с корректными статусами и в формате, удобном для фронтенда, ошибка 404 должна быть с корректным статусом и отдаваться только по несуществующим урлам, ошибки 500 не должны сыпаться через раз, сервер не должен падать по непонятным причинам и т.д.
* Линтинг, тесты, покрытие, анализ кода, логирование, деплой, мониторинг - все это должно быть уже на первом этапе
